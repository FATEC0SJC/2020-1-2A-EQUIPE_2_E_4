![topo-readME](https://user-images.githubusercontent.com/56441214/87261187-ae2e7580-c48b-11ea-91de-e2bad8f5b938.png)

![tecnologias_PI](https://user-images.githubusercontent.com/56441214/87261156-8c34f300-c48b-11ea-89cf-a96eef22661c.png)


# Projeto Integrador - Fatec São José dos Campos

Uma parceria da Fatec São José dos Campos - Prof. Jessen Vidal com uma Empresa cliente para um Projeto Integrador, onde nós alunos tivemos a oportunidade de trabalhar com uma empresa real, com problemas reais, buscar soluções e implantá-las através da metodologia SCRUM.

## - Disciplinas integradas
* ### Engenharia de Software 
  Prof. Me. Giuliano Araujo Bertoti
* ### Sistemas de Informações 
  Prof. Me. José Walmir Gonçalves Duque
* ### Linguagem de Programação
  Profª. Ma. Juliana Forin Pasquini Martiniz


## - Time
* Evandro Braga - PO
* Leonardo Messias - Scrum Master
* Fabrício Rodrigues - DEV Team
* Guilherme Madeira - DEV Team
* Mateus Prestes - DEV Team
* Pedro Mendonça - DEV Team
* Raquel Ribeiro - DEV Team


## - Objetivo

Desenvolver um produto que gere valor ao cliente e esteja em conformidade com as regras de negócio.

<a href="https://youtu.be/bPum7wufFR4">Visualizar vídeo de apresentação</a>

## - O Projeto

Desenvolvimento de uma estrutura de análise delineáveis, no formato de Aplicativo Desktop para padronização dos dados recebidos através de remessas. A ferramenta, que conta com um design intuitivo e funcional, será utilizada como *Data Preparation*, auxiliando assim, na padronização dos dados antes de serem aplicados em futuros projetos.




## - DP Standardize

![marketing_PI_11111](https://user-images.githubusercontent.com/57918707/87260544-dbc5ef80-c488-11ea-8987-faec80939a8b.png)

Você sabia que a parte mais importante e trabalhosa de um processo de Data Science é o Data Preparation?

É nessa etapa que os dados serão coletados, tratados e consolidados para que sua análise seja precisa, afinal uma má análise significa más decisões de negócios.

DP Standardize é a ferramenta ideal para sua padronização de dados, sendo capaz de analisar qualquer tabela ```xlsx``` e ```csv``` e permitindo a personalização dos campos, ou seja, informando quais tipos de dados não podem conter em cada coluna.

Ao final você pode ter gerado novas tabelas, com seus dados padronizados, prontos para a continuação da elaboração de seu futuro projeto, ou ainda dados fora dos padrões desejados, para ser devolvido à fonte e corrigidos, antes de serem usados em seu projeto.


## - Personalização dos campos

Um Analista com conhecimento nos arquivos poderá personalizar os campos, de forma que, a padronização dos seus dados seja de acordo com o necessitado.

As formas de personalização são simples: ele deverá escolher se aquele campo é requerido, único, se contém apenas caracteres numéricos, alfanuméricos ou apenas letras; poderão ser selecionadas mais de uma opção.

Posteriormente, será indicado em qual metadado essas configurações serão atribuídas, e em quais condições.

**Ex.: O Analista seleciona as checkbox requerido, alfanumérico, quando o metadado for id_mdl, sob a condição de C01.**

Feita a padronização, esses novos dados poderão ser enviados às equipes de Gestão, Marketing e Engenharia de Software, para que o desenvolvimento do produto seja colocado em prática.


## - Aplicações

DP Standardize pode ser útil em várias áreas em que o objetivo seja padronizar os dados para serem utilizados posteriormente em algum produto, como Gestão, Marketing e Engenharia de Software, por exemplo.


## - Etapas de Desenvolvimento

Para podermos otimizar o nosso trabalho, a equipe utilizou o processo de desenvolvimento da metodologia Scrum. Sendo assim, nós dividimos o processo em etapas que denominamos como Sprint.

O projeto foi divido em 6 Sprints, sendo alinhado junto ao cliente as datas e conteúdo de cada entrega, de acordo com os cards apresentados posteriormente.

Nas três primeiras sprints,estávamos focados em atingir os indicadores impostos pelo cliente, por isso, fizemos uma análise e tratamento dos dados recebidos.

À partir da quarta sprint, realinhamos as expectativas com o cliente e atualizamos alguns pontos do nosso projeto, para que pudéssemos atender à esses requisitos, desenvolvendo então a aplicação apresentada acima.


## - Tecnologias utilizadas

Ao longo do projeto tivemos contato com várias tecnologias que já possuímos certo conhecimento e algumas em que foi necessário o estudo para implementação.

No início utilizamos Python para análise dos dados e alcance dos indicadores propostos.

Posteriormente, com a necessidade do desenvolvimento de uma aplicação, pesquisamos o framework Electron, que fazia integração com o Python, porém, para melhor desempenho era necessário o uso do Javascript, então migramos para o NodeJS, e todo o design feito em HTML e CSS.


## - Diagrama de Casos de Uso

![diagrma de uso](https://user-images.githubusercontent.com/56441534/87232771-f40a1180-c397-11ea-9087-208f4eb1bd04.png)


## - Cards das Sprints

![Card_1e2](https://user-images.githubusercontent.com/56441214/87236701-cd150500-c3c2-11ea-9509-2343281f5b0c.png)

![Card_3e4](https://user-images.githubusercontent.com/56441214/87236708-d8683080-c3c2-11ea-83a6-90e63c522570.png)

![Card_5e6](https://user-images.githubusercontent.com/56441214/87236710-e1590200-c3c2-11ea-99cb-fad5ef67147c.png)


 ## - Entregas 
   
  <a href='https://github.com/EvandroRBR/Tratamento-de-dados-SPC/tree/sprint-1'> Branch 1 </a>- 16/03/2020 a 20/03/2020
  
  <a href='https://github.com/EvandroRBR/Tratamento-de-dados-SPC/tree/sprint-2'> Branch 2 </a>- 11/05/2020 a 15/05/2020
  
  <a href='https://github.com/EvandroRBR/Tratamento-de-dados-SPC/tree/sprint-3'> Branch 3 </a>- 25/05/2020 a 29/06/2020
  
  <a href='https://github.com/EvandroRBR/Tratamento-de-dados-SPC/tree/sprint-4'> Branch 4 </a>- 08/06/2020 a 14/06/2020
  
  <a href='https://github.com/EvandroRBR/Tratamento-de-dados-SPC/tree/sprint-5'> Branch 5 </a>- 22/06/2020 a 26/06/2020
  
  <a href='https://github.com/EvandroRBR/Tratamento-de-dados-SPC/tree/sprint-6'> Branch 6 </a>- 06/07/2020 a 10/07/2020
  
  
## - Requisitos necessários para o funcionamento do código
* IDE **Python 3** ou superior;
* Gerenciador de pacotes **Pip 3**;

* IDE **NODEJS 12.18.0v** ou superior;
* Gerenciador de pacotes **npm**;

* Framework **Electron 8.3.1v** ou superior;

  Para instalação em ambientes  ![linux231](https://user-images.githubusercontent.com/56441214/82009828-c11cf900-9646-11ea-8167-d60ff9696b25.jpg)
  é necessário inserir o comando:
  
  
  **Python3**
  ```
    sudo apt install python3-pip
  ``` 
  
  **NODEJS**
  
  ```
     # Using Ubuntu
     curl -sL https://deb.nodesource.com/setup_12.x | sudo -E bash -
     sudo apt-get install -y nodejs
  
     # Using Debian, as root
     curl -sL https://deb.nodesource.com/setup_12.x | bash -
     apt-get install -y nodejs
  ```
  
  **Electron**
  ```
    npm install --save-dev electron
  ```
       
  
  No Windows  ![ruindows](https://user-images.githubusercontent.com/56441214/82010155-aa2ad680-9647-11ea-942e-1195bcb956be.jpg)   assim que instalada a IDE do Python, o pip é adicionado por padrão.
  
  
  **NODEJS**
  
  ```
    https://nodejs.org/en/download/
  ```
  
  **Electron**
  ```
    npm install --save-dev electron
  ```
  
* Bibliotecas **xlrd**, **csv**, **matplotlib** e **sys** .

  Em qualquer sistema operacional, os comandos para instalar as bibliotecas xlrd e matplotlib são, respectivamente:
  
  ```pip3 install xlrd```
  
  ```pip3 install matplotlib```
  
  
  As bibliotecas **datatime**, **csv** e **sys** já vem instaladas por padrão.
